{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, r2_score\n",
    "import statistics\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adamax\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../df.csv\")\n",
    "doc2vec50 = pd.read_csv(\"../dataset/doc2vec_50.csv\")\n",
    "df_train= df[[\"essay_set\", \"essay\",\"total_score\", \"word_count\",\"Mistakes\",\"reading_ease\"]]\n",
    "df_train = doc2vec50\n",
    "df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\").drop(['Unnamed: 0'], axis = 1)\n",
    "y = df[\"total_score\"]\n",
    "X = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../df.csv\")\n",
    "doc2vec300 = pd.read_csv(\"../dataset/doc2vec_300.csv\")\n",
    "df_train= df[[\"essay_set\", \"essay\",\"total_score\", \"word_count\",\"Mistakes\",\"reading_ease\"]]\n",
    "df_train = doc2vec300\n",
    "df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\").drop(['Unnamed: 0'], axis = 1)\n",
    "y = df[\"total_score\"].values\n",
    "X = df_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(54, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 54], return_sequences=True))\n",
    "    model.add(LSTM(54, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dae9b271ddea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_emb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"essay_set\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"word_count\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Mistakes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"reading_ease\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"total_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "results = []\n",
    "r2s = []\n",
    "mses = []\n",
    "y_pred_list = []\n",
    "count = 1\n",
    "\n",
    "for num in range(1,9):\n",
    "    essay_set = pd.read_csv(\"../../dataset/cleandata_set_{}.csv\".format(num))\n",
    "    train_corpus = essay_set['essay']\n",
    "    test_corpus = train_corpus.copy()\n",
    "    vocab = CountVectorizer(stop_words='english', lowercase= True).fit(train_corpus)\n",
    "\n",
    "    # generate counts for a new set of documents\n",
    "    doc_emb = vocab.transform(train_corpus)\n",
    "    \n",
    "    vec_size = 50\n",
    "    window=2\n",
    "    min_count=1\n",
    "    workers=8\n",
    "    epochs=40\n",
    "    essays = [TaggedDocument(gensim.utils.simple_preprocess(doc), [i]) for i, doc in enumerate(train_corpus)]\n",
    "    \n",
    "    model = Doc2Vec(essays, vector_size=vec_size, window=window, min_count=min_count, workers=workers, epochs=epochs)\n",
    "    #might not need this line\n",
    "    model.train(essays, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    doc = [gensim.utils.simple_preprocess(doc) for i, doc in enumerate(test_corpus)]\n",
    "\n",
    "    doc_emb = np.zeros((len(doc), vec_size))\n",
    "    for i in range(len(doc)):\n",
    "        doc_emb[i,:] = model.infer_vector(doc[i])\n",
    "        \n",
    "    df_train = pd.DataFrame(doc_emb)\n",
    "    df_train = pd.concat([df_train, df[[\"essay_set\", \"word_count\",\"Mistakes\",\"reading_ease\"]]], axis = 1, join = \"inner\")\n",
    "    \n",
    "    y = df[\"total_score\"]\n",
    "    X = df_train\n",
    "    print(\"\\n###########Set-{}###########\\n\".format(num))\n",
    "    count = 1\n",
    "    result_for_set = []\n",
    "    for traincv, testcv in cv.split(X):\n",
    "        print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "        \n",
    "        X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "        X_train = X_train.to_numpy()\n",
    "        X_test = X_test.to_numpy()\n",
    "\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "        lstm_model = get_model()\n",
    "        lstm_model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "\n",
    "        y_pred_temp = lstm_model.predict(X_test)\n",
    "\n",
    "        y_pred = []\n",
    "        for i in y_pred_temp:\n",
    "            y_pred.append(int(round(i[0])))\n",
    "        y_pred_temp = np.around(y_pred_temp)\n",
    "        if count == 5:\n",
    "             lstm_model.save_weights('final_lstm.h5')\n",
    "        y_test_new = []\n",
    "        for  i in list(y_test.array):\n",
    "            y_test_new.append(int(i))\n",
    "        result = cohen_kappa_score(y_test_new,y_pred,weights='quadratic')\n",
    "        print(\"Kappa Score: {}\".format(result))\n",
    "        result_for_set.append(result)\n",
    "        count += 1\n",
    "    results.append(result_for_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.107725 -0.382557  1.334837 -0.180234 -0.114252  0.654670 -0.951697   \n",
      "1     0.559967  1.035295  0.166422  0.516241 -0.084778  0.942859 -0.597336   \n",
      "2    -0.564991  0.252604  0.235742  0.760749  1.144909  0.261184 -1.308746   \n",
      "3     1.101475 -0.231672  1.340678  1.060182 -2.239716  1.058062 -0.183254   \n",
      "4    -0.263135  0.525271  0.858397  0.369867 -0.826594  1.089485 -0.265835   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1778 -0.175561  0.701745  2.341178  0.783649  3.520728  0.732004 -1.378145   \n",
      "1779 -0.114634 -0.071539  0.986146  1.384397 -0.938375  1.962089  0.069004   \n",
      "1780 -1.829511 -0.515405  2.013804 -0.271621 -0.811980  0.712048 -1.395960   \n",
      "1781 -0.337402  0.022656  1.072508  0.335590  0.377162  0.357291 -0.615945   \n",
      "1782  0.757166 -0.499682  1.190086  1.425673 -0.309289  0.857285 -1.217730   \n",
      "\n",
      "            7         8         9   ...        40        41        42  \\\n",
      "0    -0.224787  0.040965 -0.843638  ...  0.937353 -0.400949  1.287803   \n",
      "1     0.411991 -2.158776 -0.679556  ... -0.480793 -0.303379 -0.019111   \n",
      "2     2.210271 -0.412710  0.441878  ... -0.204836 -0.176328  0.812478   \n",
      "3    -0.024220  0.299182 -0.916986  ...  1.526447  0.514384  0.321089   \n",
      "4     0.297133  0.252317  0.021404  ... -1.519008  1.184197 -0.323988   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1778  0.120360  1.105345  0.922058  ... -2.943353  0.243124  0.174631   \n",
      "1779 -0.631440 -0.911913 -1.294473  ... -0.322299 -1.209081  1.431970   \n",
      "1780 -1.253502 -0.664481  0.956824  ... -0.166126  0.310443  0.698046   \n",
      "1781 -0.099364 -0.226351 -0.221137  ...  0.055058 -0.472362 -0.140458   \n",
      "1782 -0.595158 -1.145534  0.109847  ...  0.680008  0.679276  0.600761   \n",
      "\n",
      "            43        44        45        46        47        48        49  \n",
      "0     1.257948 -1.301827  2.263631 -1.263495  0.795735  1.073001  0.836720  \n",
      "1    -0.872209 -1.745343 -0.732597  0.781754 -0.598151 -1.945872 -0.411754  \n",
      "2     0.176507 -0.140534  0.423900  0.987976 -2.376521 -0.084392  0.270826  \n",
      "3    -0.907932 -3.054509  1.124765  2.748112 -1.148175 -0.519899 -1.526839  \n",
      "4    -1.739493 -0.848546 -0.604337  0.436804  0.166750 -0.406647 -0.893972  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1778  1.362142 -0.283435  0.298813  0.057302 -0.958830  2.594693  2.063621  \n",
      "1779  0.872332 -0.576501  0.198636  1.344952 -1.013382  0.593575  1.234037  \n",
      "1780  0.104880  1.055226  0.748817  2.387617 -0.934719  0.118518 -0.765142  \n",
      "1781  0.528783 -0.461957 -0.096008  0.422594 -0.509820 -0.395646  0.580811  \n",
      "1782 -0.631349 -1.775276  0.473447 -0.481765 -1.648876  1.949309 -1.077218  \n",
      "\n",
      "[1783 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay set 1\n",
      "0.7430904524409885\n",
      "Essay set 2\n",
      "0.6430423972736458\n",
      "Essay set 3\n",
      "0.608976790928228\n",
      "Essay set 4\n",
      "0.6923776715581466\n",
      "Essay set 5\n",
      "0.6636116129139091\n",
      "Essay set 6\n",
      "0.6727591464636252\n",
      "Essay set 7\n",
      "0.7504665038869414\n",
      "Essay set 8\n",
      "0.0019747832427356336\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(\"Essay set {}\".format(i+1))\n",
    "    print(np.mean(results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.53643310e-01,  1.22631383e+00,  1.49060738e+00, ...,\n",
       "         3.38000000e+02,  2.00000000e+01,  7.40200000e+01],\n",
       "       [ 1.78830183e+00, -5.99211633e-01, -2.10853004e+00, ...,\n",
       "         4.19000000e+02,  3.30000000e+01,  6.70800000e+01],\n",
       "       [-2.45267693e-02,  5.21169484e-01, -8.56822908e-01, ...,\n",
       "         2.79000000e+02,  2.00000000e+01,  6.82000000e+01],\n",
       "       ...,\n",
       "       [ 1.19136560e+00,  9.73212183e-01, -5.47442257e-01, ...,\n",
       "         8.18000000e+02,  8.20000000e+01,  6.92500000e+01],\n",
       "       [ 4.18220490e-01,  1.79089689e+00,  5.47983468e-01, ...,\n",
       "         5.94000000e+02,  3.30000000e+01,  7.20500000e+01],\n",
       "       [-8.03048015e-02,  1.26649606e+00,  1.87341690e-01, ...,\n",
       "         4.68000000e+02,  1.10000000e+01,  7.20500000e+01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[df[\"essay_set\"] == j][\"total_score\"]\n",
    "X = df_train.loc[df_train[\"essay_set\"] == j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        8.0\n",
       "1        9.0\n",
       "2        7.0\n",
       "3       10.0\n",
       "4        8.0\n",
       "        ... \n",
       "1778     8.0\n",
       "1779     7.0\n",
       "1780     8.0\n",
       "1781     2.0\n",
       "1782     7.0\n",
       "Name: total_score, Length: 1783, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Mistakes</th>\n",
       "      <th>reading_ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.653643</td>\n",
       "      <td>1.226314</td>\n",
       "      <td>1.490607</td>\n",
       "      <td>-0.273509</td>\n",
       "      <td>-0.126667</td>\n",
       "      <td>1.948407</td>\n",
       "      <td>-0.800371</td>\n",
       "      <td>-0.520892</td>\n",
       "      <td>-1.989100</td>\n",
       "      <td>0.305569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436761</td>\n",
       "      <td>1.510649</td>\n",
       "      <td>-0.300369</td>\n",
       "      <td>-0.430754</td>\n",
       "      <td>-1.164265</td>\n",
       "      <td>0.293608</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.788302</td>\n",
       "      <td>-0.599212</td>\n",
       "      <td>-2.108530</td>\n",
       "      <td>0.105541</td>\n",
       "      <td>-0.419768</td>\n",
       "      <td>0.424503</td>\n",
       "      <td>0.306117</td>\n",
       "      <td>-1.297395</td>\n",
       "      <td>-0.365960</td>\n",
       "      <td>-0.193469</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.120824</td>\n",
       "      <td>0.798896</td>\n",
       "      <td>-0.735984</td>\n",
       "      <td>-1.692172</td>\n",
       "      <td>-0.989390</td>\n",
       "      <td>1.180730</td>\n",
       "      <td>1</td>\n",
       "      <td>419</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024527</td>\n",
       "      <td>0.521169</td>\n",
       "      <td>-0.856823</td>\n",
       "      <td>-0.467126</td>\n",
       "      <td>-0.856623</td>\n",
       "      <td>0.542416</td>\n",
       "      <td>-1.578355</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>-1.748438</td>\n",
       "      <td>-0.108801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789562</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>-1.198619</td>\n",
       "      <td>1.141882</td>\n",
       "      <td>-0.438716</td>\n",
       "      <td>-0.378533</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>20.0</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.232087</td>\n",
       "      <td>0.245010</td>\n",
       "      <td>-0.081397</td>\n",
       "      <td>2.165611</td>\n",
       "      <td>-1.296768</td>\n",
       "      <td>0.386925</td>\n",
       "      <td>-1.609302</td>\n",
       "      <td>0.097405</td>\n",
       "      <td>-2.632485</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900712</td>\n",
       "      <td>1.323254</td>\n",
       "      <td>-1.008070</td>\n",
       "      <td>-2.154635</td>\n",
       "      <td>1.147291</td>\n",
       "      <td>1.223645</td>\n",
       "      <td>1</td>\n",
       "      <td>524</td>\n",
       "      <td>68.0</td>\n",
       "      <td>53.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.532192</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>-1.994325</td>\n",
       "      <td>0.103210</td>\n",
       "      <td>-1.187608</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>0.119099</td>\n",
       "      <td>0.494659</td>\n",
       "      <td>-0.015966</td>\n",
       "      <td>1.025912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127415</td>\n",
       "      <td>-0.186732</td>\n",
       "      <td>-2.030141</td>\n",
       "      <td>-2.104558</td>\n",
       "      <td>0.112237</td>\n",
       "      <td>-0.022088</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0.076996</td>\n",
       "      <td>1.060306</td>\n",
       "      <td>-0.374213</td>\n",
       "      <td>-0.734702</td>\n",
       "      <td>0.987911</td>\n",
       "      <td>3.004169</td>\n",
       "      <td>1.927672</td>\n",
       "      <td>0.183494</td>\n",
       "      <td>-2.541197</td>\n",
       "      <td>0.138758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343130</td>\n",
       "      <td>0.955492</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>-0.262129</td>\n",
       "      <td>-1.845663</td>\n",
       "      <td>-2.069562</td>\n",
       "      <td>1</td>\n",
       "      <td>497</td>\n",
       "      <td>46.0</td>\n",
       "      <td>77.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0.526733</td>\n",
       "      <td>2.083623</td>\n",
       "      <td>-1.318357</td>\n",
       "      <td>0.365669</td>\n",
       "      <td>0.885012</td>\n",
       "      <td>1.430439</td>\n",
       "      <td>-0.444463</td>\n",
       "      <td>0.419993</td>\n",
       "      <td>-1.443482</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>...</td>\n",
       "      <td>1.393086</td>\n",
       "      <td>1.244183</td>\n",
       "      <td>-1.869425</td>\n",
       "      <td>-1.892759</td>\n",
       "      <td>-1.115894</td>\n",
       "      <td>-0.072377</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>17.0</td>\n",
       "      <td>84.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0.258367</td>\n",
       "      <td>0.962929</td>\n",
       "      <td>1.196177</td>\n",
       "      <td>-0.475155</td>\n",
       "      <td>-1.180123</td>\n",
       "      <td>2.435375</td>\n",
       "      <td>-0.833579</td>\n",
       "      <td>0.755691</td>\n",
       "      <td>0.030383</td>\n",
       "      <td>1.244768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655146</td>\n",
       "      <td>-0.589399</td>\n",
       "      <td>-1.204976</td>\n",
       "      <td>1.377089</td>\n",
       "      <td>0.634938</td>\n",
       "      <td>-0.676763</td>\n",
       "      <td>1</td>\n",
       "      <td>291</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0.092214</td>\n",
       "      <td>0.710328</td>\n",
       "      <td>0.870210</td>\n",
       "      <td>-0.486119</td>\n",
       "      <td>-0.559627</td>\n",
       "      <td>0.609152</td>\n",
       "      <td>0.108019</td>\n",
       "      <td>0.114833</td>\n",
       "      <td>-0.310847</td>\n",
       "      <td>0.426044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377715</td>\n",
       "      <td>0.458104</td>\n",
       "      <td>-0.948134</td>\n",
       "      <td>-0.174676</td>\n",
       "      <td>-0.203892</td>\n",
       "      <td>-0.439191</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>-0.372615</td>\n",
       "      <td>0.728097</td>\n",
       "      <td>-0.096739</td>\n",
       "      <td>0.141957</td>\n",
       "      <td>-0.251851</td>\n",
       "      <td>-0.035748</td>\n",
       "      <td>-1.283910</td>\n",
       "      <td>1.236656</td>\n",
       "      <td>-1.723650</td>\n",
       "      <td>0.964451</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117982</td>\n",
       "      <td>0.623014</td>\n",
       "      <td>-1.433479</td>\n",
       "      <td>-1.176527</td>\n",
       "      <td>-0.433444</td>\n",
       "      <td>0.682913</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>20.0</td>\n",
       "      <td>76.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.653643  1.226314  1.490607 -0.273509 -0.126667  1.948407 -0.800371   \n",
       "1     1.788302 -0.599212 -2.108530  0.105541 -0.419768  0.424503  0.306117   \n",
       "2    -0.024527  0.521169 -0.856823 -0.467126 -0.856623  0.542416 -1.578355   \n",
       "3     2.232087  0.245010 -0.081397  2.165611 -1.296768  0.386925 -1.609302   \n",
       "4    -0.532192 -0.046631 -1.994325  0.103210 -1.187608  0.603498  0.119099   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1778  0.076996  1.060306 -0.374213 -0.734702  0.987911  3.004169  1.927672   \n",
       "1779  0.526733  2.083623 -1.318357  0.365669  0.885012  1.430439 -0.444463   \n",
       "1780  0.258367  0.962929  1.196177 -0.475155 -1.180123  2.435375 -0.833579   \n",
       "1781  0.092214  0.710328  0.870210 -0.486119 -0.559627  0.609152  0.108019   \n",
       "1782 -0.372615  0.728097 -0.096739  0.141957 -0.251851 -0.035748 -1.283910   \n",
       "\n",
       "             7         8         9  ...        44        45        46  \\\n",
       "0    -0.520892 -1.989100  0.305569  ...  1.436761  1.510649 -0.300369   \n",
       "1    -1.297395 -0.365960 -0.193469  ... -1.120824  0.798896 -0.735984   \n",
       "2    -0.025513 -1.748438 -0.108801  ... -0.789562  0.019656 -1.198619   \n",
       "3     0.097405 -2.632485  0.009429  ... -0.900712  1.323254 -1.008070   \n",
       "4     0.494659 -0.015966  1.025912  ...  0.127415 -0.186732 -2.030141   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1778  0.183494 -2.541197  0.138758  ...  0.343130  0.955492  0.042598   \n",
       "1779  0.419993 -1.443482  0.104980  ...  1.393086  1.244183 -1.869425   \n",
       "1780  0.755691  0.030383  1.244768  ... -0.655146 -0.589399 -1.204976   \n",
       "1781  0.114833 -0.310847  0.426044  ...  0.377715  0.458104 -0.948134   \n",
       "1782  1.236656 -1.723650  0.964451  ...  1.117982  0.623014 -1.433479   \n",
       "\n",
       "            47        48        49  essay_set  word_count  Mistakes  \\\n",
       "0    -0.430754 -1.164265  0.293608          1         338      20.0   \n",
       "1    -1.692172 -0.989390  1.180730          1         419      33.0   \n",
       "2     1.141882 -0.438716 -0.378533          1         279      20.0   \n",
       "3    -2.154635  1.147291  1.223645          1         524      68.0   \n",
       "4    -2.104558  0.112237 -0.022088          1         465      23.0   \n",
       "...        ...       ...       ...        ...         ...       ...   \n",
       "1778 -0.262129 -1.845663 -2.069562          1         497      46.0   \n",
       "1779 -1.892759 -1.115894 -0.072377          1         200      17.0   \n",
       "1780  1.377089  0.634938 -0.676763          1         291      14.0   \n",
       "1781 -0.174676 -0.203892 -0.439191          1          15       0.0   \n",
       "1782 -1.176527 -0.433444  0.682913          1         214      20.0   \n",
       "\n",
       "      reading_ease  \n",
       "0            74.02  \n",
       "1            67.08  \n",
       "2            68.20  \n",
       "3            53.34  \n",
       "4            72.66  \n",
       "...            ...  \n",
       "1778         77.30  \n",
       "1779         84.88  \n",
       "1780         71.04  \n",
       "1781         90.09  \n",
       "1782         76.42  \n",
       "\n",
       "[1783 rows x 54 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
